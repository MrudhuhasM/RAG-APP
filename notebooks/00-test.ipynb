{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af26b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrudh\\Documents\\Projects\\ProfileProject\\rag_app\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from rag_app.services.ingest import IngestionService\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "from rag_app.embeddings import get_chunk_embeddings, get_embed_model\n",
    "from openai import OpenAI\n",
    "from rag_app.config.settings import settings\n",
    "from rag_app.core.vector_client import VectorClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6cd44aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-20 18:39:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.embeddings\u001b[0m:\u001b[36mget_chunk_embeddings\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mUsing llama-index Local Embedding Model\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.embeddings\u001b[0m:\u001b[36mget_embed_model\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mInitializing Local Models Embedding Model\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_ingest_file\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mLoading documents from C:/Users/mrudh/Documents/Data/CWMG-KS-Vol-001-I.pdf\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_ingest_file\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mLoaded 457 documents.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_preprocess_documents\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mPreprocessing documents...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_preprocess_documents\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mPreprocessed documents. 457 -> 422\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_chunk_documents\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mChunking 4 documents into nodes...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_chunk_documents\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mChunked documents into 8 nodes.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:39:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_process_nodes\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mExtracting metadata for nodes...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_process_nodes\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mMetadata extraction completed.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_embed_nodes\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mEmbedding nodes...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_embed_nodes\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mEmbedding completed.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_upsert_nodes\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mUpserting 8 nodes to vector database...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_upsert_nodes\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mUpsert completed.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_upsert_questions\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mUpserting questions from 8 nodes to namespace 'questions'...\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36m_upsert_questions\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mUpserted 40 question vectors.\u001b[0m\n",
      "\u001b[32m2025-10-20 18:41:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.services.ingest\u001b[0m:\u001b[36mingest\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mIngestion completed in 119.39 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reader = PyMuPDFReader()\n",
    "chunk_embed_model = get_chunk_embeddings()\n",
    "embedding_client = get_embed_model()\n",
    "client = OpenAI(base_url=settings.local_models.completion_base_url, api_key=\"test\")\n",
    "vector_client = VectorClient(\n",
    "    api_key=settings.pinecone.api_key,\n",
    "    environment=settings.pinecone.environment,\n",
    "    index_name=settings.pinecone.index_name,\n",
    "    dimension=settings.pinecone.dimension,\n",
    "    metric=settings.pinecone.metric,\n",
    "    cloud=settings.pinecone.cloud,\n",
    "    region=settings.pinecone.region,\n",
    ")\n",
    "\n",
    "\n",
    "node_parser = SemanticSplitterNodeParser(embed_model=chunk_embed_model)\n",
    "\n",
    "ingest_service = IngestionService(\n",
    "    reader=reader,\n",
    "    node_parser=node_parser,\n",
    "    client=client,\n",
    "    vector_client=vector_client,\n",
    "    embedding_client=embedding_client,\n",
    ")\n",
    "\n",
    "nodes = ingest_service.ingest(file_path=\"C:/Users/mrudh/Documents/Data/CWMG-KS-Vol-001-I.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff810fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ xxiii ] \\nand in abundance, thus bringing down the prices of the white \\nfarmer. The Indian trader lived cheaply, spent little on equipment \\nor staff, and, could easily undersell the British and the Dutch. \\nThe whites, therefore, feared that they would be swamped by \\nthe Indians, if the Indians were allowed to enter the country freely \\nand establish themselves on land, or trade as they pleased. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86766dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-app (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
