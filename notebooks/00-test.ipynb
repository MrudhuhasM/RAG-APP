{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all handlers first to start fresh\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "import torch\n",
    "\n",
    "from rag_app.services.rag import RagService\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from rag_app.services.ingest import IngestionService\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "from rag_app.embeddings import get_chunk_embeddings, get_embed_model\n",
    "from openai import AsyncOpenAI\n",
    "from rag_app.config.settings import settings\n",
    "from rag_app.core.vector_client import VectorClient\n",
    "from rag_app.llm import get_llm_model\n",
    "from sentence_transformers import CrossEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8becb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "reader = PyMuPDFReader()\n",
    "chunk_embed_model = get_chunk_embeddings()\n",
    "embedding_client = get_embed_model()\n",
    "\n",
    "llm_model = get_llm_model()\n",
    "\n",
    "vector_client = await VectorClient.create(\n",
    "    api_key=settings.pinecone.api_key,\n",
    "    environment=settings.pinecone.environment,\n",
    "    index_name=settings.pinecone.index_name,\n",
    "    dimension=settings.pinecone.dimension,\n",
    "    metric=settings.pinecone.metric,\n",
    "    cloud=settings.pinecone.cloud,\n",
    "    region=settings.pinecone.region,\n",
    ")\n",
    "\n",
    "encoder_model = CrossEncoder(settings.reranker.model, device=\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "\n",
    "\n",
    "node_parser = SemanticSplitterNodeParser(embed_model=chunk_embed_model)\n",
    "\n",
    "ingest_service = IngestionService(\n",
    "    reader=reader,\n",
    "    node_parser=node_parser,\n",
    "    llm_model=llm_model,\n",
    "    vector_client=vector_client,\n",
    "    embedding_client=embedding_client,\n",
    ")\n",
    "\n",
    "rag_service = RagService(\n",
    "    embed_model=embedding_client,\n",
    "    vector_client=vector_client,\n",
    "    llm_model=llm_model,\n",
    "    encoder_model=encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = await ingest_service.ingest(file_path=\"C:/Users/mrudh/Documents/Data/CWMG-KS-Vol-001-I.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was Gandhiâ€™s early argument in favor of vegetarianism?\"\n",
    "matches = await rag_service.answer_query(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8087858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matches['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['sources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "result = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=\"What is the meaning of life?\")\n",
    "\n",
    "print(result.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58fa612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_app.llm import get_llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad00c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-23 11:18:27.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.llm\u001b[0m:\u001b[36mget_llm_model\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mInitializing Local LLM\u001b[0m\n",
      "\u001b[32m2025-10-23 11:18:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_app.llm\u001b[0m:\u001b[36mget_llm_model\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mInitializing Local LLM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_llm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78b8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# from openai import AsyncOpenAI\n",
    "\n",
    "# client = AsyncOpenAI(base_url=\"http://localhost:8080/v1\", api_key=\"test\")\n",
    "\n",
    "from rag_app.schemas.metadata import QuestionMetadata\n",
    "\n",
    "node = \"\"\"to the captain. He reproved these pugilistic gentlemen, and ever\n",
    "since then we had no more rows.\n",
    "Thus, dividing our time between eating and amusements,\n",
    "we moved onward.\n",
    "After two days' voyage, the steamer passed by, but did not\n",
    "touch,\n",
    "Gibraltar.\n",
    "This caused much disappointment,\n",
    "mostly\n",
    "among smokers, who wanted to get tobacco, duty-free in Gibral-\n",
    "tar, as some of us had entertained a hope the steamer would cast\n",
    "anchor.\n",
    "The next place reached was Malta. It being a coaling sta-\n",
    "tion, the steamer stops there for about nine hours. Almost all the\n",
    "passengers went ashore.\n",
    "Malta is a beautiful island without the London smoke. The\n",
    "construction of houses is different. We had a look round the Gover-\n",
    "nor's palace. The armoury is well worth a visit. Napoleon's car-\n",
    "riage is on view there. You see there some beautiful paintings\n",
    "too. The market is not bad. The fruit is cheap. The cathedral is\n",
    "magnificent.\n",
    "We had a nice drive of about six miles to the orange gar-\n",
    "den. There you see some thousands of orange trees and some\n",
    "ponds with gold fish. The drive was very cheap, only 2s. 6d.\n",
    "What a wretched place Malta is for beggars! You cannot go\n",
    "along the road quietly without being pestered by a crowd of dirty-\n",
    "looking beggars. Some would offer to be your guides, others would\n",
    "offer to take you to shops where you could buy cigars or the famous\n",
    "Maltese sweet nougat.\n",
    "From Malta we reached Brindisi. It is a good harbour and\n",
    "that is all. You cannot pass a single day in amusement. We had\n",
    "about nine hours or more at our disposal, but we could not uti-\n",
    "lize even four.\n",
    "After Brindisi we reached Port Said.\n",
    "There we took final\n",
    "leave of Europe and the Mediterranean. Of course, there is no-\n",
    "thing to be seen in Port Said, unless you want to see the dregs of\n",
    "society. It is full of rogues and rascals.\n",
    "From Port Said the steamer moves along very slowly, for we\n",
    "enter the Suez Canal of M. de Lesseps. It is a distance of eighty-\n",
    "seven miles. The steamer took nearly twenty-four hours to travel\n",
    "that distance. We were close to the land on both sides. The strip\n",
    "of water is so narrow that two steamers cannot go abreast except\n",
    "at certain places. At night the sight is charming. All the ships are\n",
    "required to light electric lights in front and these are very power-\n",
    "ful. The scene when two pass one another is very pleasant. The\n",
    "electric light you get from the opposite ship is simply dazzling.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with a chunk of text from a document.\n",
    "Your task is to extract 5 questions that can be answered using the information in the text.\n",
    "you will answer in the following json format\n",
    "You should only respond with the JSON object and nothing else.no other text.this is very important.\n",
    "Only output 5 questions not more not less. \n",
    "\"\"\"\n",
    "\n",
    "# input_messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts questions from text.\"},\n",
    "#     {\"role\": \"user\", \"content\": prompt}\n",
    "#     ]\n",
    "\n",
    "\n",
    "# result = await model.generate_completion(\n",
    "#     messages=input_messages,\n",
    "#     structured_format=QuestionMetadata,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623773bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_app.config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dacdf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.llm.provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50a0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LLM_PROVIDER'] = 'openai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c42f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.llm.provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3419c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-app (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
